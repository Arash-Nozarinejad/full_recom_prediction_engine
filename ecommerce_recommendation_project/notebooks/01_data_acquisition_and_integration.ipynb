{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb753f85-7548-48fc-ba4f-2eac52aee064",
   "metadata": {},
   "source": [
    "# E-commerce Customer Behavior Prediction and Recommendation Engine\n",
    "## Notebook 1: Data Acquisition and Integration\n",
    "\n",
    "This notebook focuses on the critical first step: establishing a robust data acquisition and integration pipeline that will form the foundation for all subsequent analyses and modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3312573-432d-4f76-b189-53d3ff931cad",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Before diving into data acquisition, let's set up our environment with the necessary libraries and configurations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ba0b28-38b6-4ad1-a46e-3b84f4f3ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import logging\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "import glob\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import zipfile\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Determine the project root.\n",
    "# If running in a Jupyter notebook, assume the current working directory is 'notebooks'\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1] if '__file__' in globals() else Path.cwd().parent\n",
    "\n",
    "# Load environment variables from the .env file located in the project root\n",
    "load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "# Configure warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure the logs directory exists (located at PROJECT_ROOT/logs)\n",
    "log_dir = PROJECT_ROOT / \"logs\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set up logging to track our data acquisition process.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_dir / \"data_acquisition.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"DataAcquisition\")\n",
    "\n",
    "# Set display options for better readability of dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "# Set random seed for reproducibility across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388ed0e6-38aa-4fb7-8f0e-89148ed96786",
   "metadata": {},
   "source": [
    "## Project Directory Structure\n",
    "\n",
    "Let's create a well-organized project structure to maintain clean separation between raw data, processed data, models, and outputs. This follows data science best practices and will make our project more maintainable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c87b147d-067f-4415-8703-441370a2d54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 12:15:32,182 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\data\\raw\n",
      "2025-03-26 12:15:32,184 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\data\\processed\n",
      "2025-03-26 12:15:32,187 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\data\\interim\n",
      "2025-03-26 12:15:32,188 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\models\n",
      "2025-03-26 12:15:32,192 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\outputs\n",
      "2025-03-26 12:15:32,194 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\logs\n",
      "2025-03-26 12:15:32,195 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\reports\n",
      "2025-03-26 12:15:32,196 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\notebooks\n",
      "2025-03-26 12:15:32,197 - DataAcquisition - INFO - Created directory: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\configs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Directory Structure Created:\n",
      "- raw_data: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\data\\raw\n",
      "- processed_data: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\data\\processed\n",
      "- interim_data: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\data\\interim\n",
      "- models: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\models\n",
      "- outputs: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\outputs\n",
      "- logs: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\logs\n",
      "- reports: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\reports\n",
      "- notebooks: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\notebooks\n",
      "- configs: C:\\_Arash\\github\\ecom-reco-predictor\\full_recom_prediction_engine\\ecommerce_recommendation_project\\configs\n"
     ]
    }
   ],
   "source": [
    "# Create project directory structure\n",
    "def create_project_structure(base_dir: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Creates a standardized project directory structure for organizing data and outputs.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: The base directory for the project (as a Path object)\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary mapping directory names to their paths (as Path objects)\n",
    "    \"\"\"\n",
    "    directories = {\n",
    "        \"raw_data\": base_dir / \"data\" / \"raw\",           # Original, immutable data\n",
    "        \"processed_data\": base_dir / \"data\" / \"processed\", # Cleaned and transformed data\n",
    "        \"interim_data\": base_dir / \"data\" / \"interim\",     # Temporary data between processing steps\n",
    "        \"models\": base_dir / \"models\",                     # Trained models and model artifacts\n",
    "        \"outputs\": base_dir / \"outputs\",                   # Analysis outputs and visualizations\n",
    "        \"logs\": base_dir / \"logs\",                         # Logs from various processes\n",
    "        \"reports\": base_dir / \"reports\",                   # Generated analysis reports\n",
    "        \"notebooks\": base_dir / \"notebooks\",               # Jupyter notebooks\n",
    "        \"configs\": base_dir / \"configs\"                    # Configuration files\n",
    "    }\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    for name, dir_path in directories.items():\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        logger.info(f\"Created directory: {dir_path}\")\n",
    "    \n",
    "    return directories\n",
    "\n",
    "# Use the previously defined PROJECT_ROOT from the earlier code block\n",
    "project_dirs = create_project_structure(PROJECT_ROOT)\n",
    "\n",
    "# Display the project structure\n",
    "# print(\"Project Directory Structure Created:\")\n",
    "# for name, path in project_dirs.items():\n",
    "    # print(f\"- {name}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880abb9-f393-4df2-b2e0-e985284eb2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
